{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fb455-6fb4-4537-9e55-165f92809549",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install astropy==6.1.4 parfive==2.1.0 Glymur==0.13.6 aiapy==0.7.4 numpy hvpy opencv-python==4.10.0.84 ultralytics torch wandb matplotlib==3.7.1 sunpy \"numpy<2.0\" --no-cache-dir h5py pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed2998-e0c0-4ee3-a863-314b6116ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party libraries\n",
    "import aiohttp\n",
    "import astropy.units as u\n",
    "import cv2\n",
    "import hvpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from astropy.coordinates import SkyCoord\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from sunpy.map import Map\n",
    "from aiapy.calibrate import normalize_exposure\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b721074-e31d-4985-a01e-86b7aa8e8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory setup\n",
    "base_folder = 'data/roloro'\n",
    "jp2_folder = os.path.join(base_folder, 'jp2')\n",
    "train_images_folder = os.path.join(base_folder, 'train/images')\n",
    "train_labels_folder = os.path.join(base_folder, 'train/labels')\n",
    "val_images_folder = os.path.join(base_folder, 'val/images')\n",
    "val_labels_folder = os.path.join(base_folder, 'val/labels')\n",
    "test_images_folder = os.path.join(base_folder, 'test/images')\n",
    "test_labels_folder = os.path.join(base_folder, 'test/labels')\n",
    "annotated_folder = os.path.join(base_folder, 'annotated')\n",
    "\n",
    "# Create folders if they do not exist\n",
    "os.makedirs(jp2_folder, exist_ok=True)\n",
    "os.makedirs(train_images_folder, exist_ok=True)\n",
    "os.makedirs(train_labels_folder, exist_ok=True)\n",
    "os.makedirs(val_images_folder, exist_ok=True)\n",
    "os.makedirs(val_labels_folder, exist_ok=True)\n",
    "os.makedirs(test_images_folder, exist_ok=True)\n",
    "os.makedirs(test_labels_folder, exist_ok=True)\n",
    "os.makedirs(annotated_folder, exist_ok=True)\n",
    "\n",
    "output_folders = [\n",
    "    (train_images_folder, train_labels_folder),\n",
    "    (val_images_folder, val_labels_folder),\n",
    "    (test_images_folder, test_labels_folder)\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"ribbondb_v1.0.csv\")\n",
    "source_id = hvpy.getDataSources()['SDO']['AIA']['1600']['sourceId']\n",
    "\n",
    "# Define the number of rows to process (set to None to process all rows)\n",
    "num_rows = 10  # Set to None to process the entire dataset\n",
    "\n",
    "# Determine the number of rows to process\n",
    "if num_rows is None:\n",
    "    num_rows = len(data)\n",
    "\n",
    "print(f\"Processing {num_rows} rows from the dataset...\")\n",
    "\n",
    "# Helper function to determine output folder based on index\n",
    "def get_output_folder(index):\n",
    "    # Assign 70% for train, 20% for val, 10% for test\n",
    "    if index % 10 < 7:\n",
    "        return output_folders[0]  # Train\n",
    "    elif index % 10 < 9:\n",
    "        return output_folders[1]  # Validation\n",
    "    else:\n",
    "        return output_folders[2]  # Test\n",
    "\n",
    "# Helper function to check files in folders\n",
    "def check_files_in_folders(start_time, end_time):\n",
    "    # Generate a list of expected file names based on the time range\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq='min')\n",
    "    expected_files = [f\"{timestamp.strftime('%Y-%m-%dT%H-%M-%S')}_AIA1600.png\" for timestamp in time_range]\n",
    "    \n",
    "    # Dictionary to store folder locations for each file\n",
    "    file_locations = {file: [] for file in expected_files}\n",
    "    \n",
    "    # Search for each file in the output folders\n",
    "    for images_folder, _ in output_folders:\n",
    "        for file in expected_files:\n",
    "            if os.path.exists(os.path.join(images_folder, file)):\n",
    "                file_locations[file].append(images_folder)\n",
    "    \n",
    "    # Check if files from the same interval are in multiple folders\n",
    "    for file, locations in file_locations.items():\n",
    "        if len(locations) > 1:\n",
    "            print(f\"File {file} is found in multiple folders: {locations}\")\n",
    "    \n",
    "    # Return True if all files are in a single folder\n",
    "    return all(len(locations) <= 1 for locations in file_locations.values())\n",
    "\n",
    "# Step 1: Download and preprocess images\n",
    "print(\"Starting image download and preprocessing...\")\n",
    "for index, row in data.iterrows():\n",
    "    if index >= num_rows:\n",
    "        break\n",
    "\n",
    "    lat = row[' LAT [deg]']\n",
    "    lon = row[' LON [deg]']\n",
    "    start_time = f\"{row[' TSTART [UT]']}:00\"\n",
    "    end_time = f\"{row[' TFINAL [UT]']}:00\"\n",
    "    \n",
    "    # Create time range\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq='min')\n",
    "\n",
    "    # Define bounding box coordinates in SkyCoord\n",
    "    top_right = SkyCoord((lon - 20) * u.deg, (lat + 20) * u.deg, frame='heliographic_stonyhurst')\n",
    "    bottom_left = SkyCoord((lon + 20) * u.deg, (lat - 20) * u.deg, frame='heliographic_stonyhurst')\n",
    "\n",
    "    for timestamp in time_range:\n",
    "        date_str = timestamp.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        jp2_filename = os.path.join(jp2_folder, f'{date_str.replace(\":\", \"-\")}_AIA1600.jp2')\n",
    "        \n",
    "        # Check if JP2 file already exists \n",
    "        if os.path.exists(jp2_filename):\n",
    "            print(f\"File already exists: {jp2_filename}. Skipping download.\")\n",
    "            continue\n",
    "\n",
    "print(\"Image download completed.\")\n",
    "\n",
    "# Step 2: Process images to PNG and create YOLO annotations\n",
    "print(\"Starting image processing and annotation creation...\")\n",
    "for index, row in data.iterrows():\n",
    "    if index >= num_rows:\n",
    "        break\n",
    "\n",
    "    lat = row[' LAT [deg]']\n",
    "    lon = row[' LON [deg]']\n",
    "    start_time = f\"{row[' TSTART [UT]']}:00\"\n",
    "    end_time = f\"{row[' TFINAL [UT]']}:00\"\n",
    "    \n",
    "    # Create time range\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq='min')\n",
    "\n",
    "    # Determine the output folder (train/val/test)\n",
    "    images_folder, labels_folder = get_output_folder(index)\n",
    "\n",
    "    for timestamp in time_range:\n",
    "        date_str = timestamp.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        jp2_filename = os.path.join(jp2_folder, f'{date_str.replace(\":\", \"-\")}_AIA1600.jp2')\n",
    "        \n",
    "        # Check if JP2 file exists\n",
    "        if not os.path.exists(jp2_filename):\n",
    "            print(f\"JP2 file not found: {jp2_filename}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Process image with sunpy\n",
    "            solar_map = Map(jp2_filename)\n",
    "            solar_map = normalize_exposure(solar_map)\n",
    "            \n",
    "            # Convert image data to 8-bit PNG\n",
    "            data = solar_map.data.astype(np.float32)\n",
    "            data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            data = ((data - data.min()) / (data.max() - data.min()) * 255).astype(np.uint8)\n",
    "            image_filename = os.path.join(images_folder, f'{date_str.replace(\":\", \"-\")}_AIA1600.png')\n",
    "\n",
    "            # Ensure the folder for the image exists\n",
    "            os.makedirs(os.path.dirname(image_filename), exist_ok=True)\n",
    "\n",
    "            # Save the image\n",
    "            Image.fromarray(data).save(image_filename)\n",
    "\n",
    "            # Calculate YOLO annotations\n",
    "            orig_img_height, orig_img_width = data.shape\n",
    "            bottom_left = SkyCoord((lon + 20) * u.deg, (lat - 20) * u.deg, frame=solar_map.coordinate_frame)\n",
    "            top_right = SkyCoord((lon - 20) * u.deg, (lat + 20) * u.deg, frame=solar_map.coordinate_frame)\n",
    "            bottom_left_pix = solar_map.world_to_pixel(bottom_left)\n",
    "            top_right_pix = solar_map.world_to_pixel(top_right)\n",
    "\n",
    "            x_center = ((bottom_left_pix.x.value + top_right_pix.x.value) / 2) / orig_img_width\n",
    "            y_center = ((bottom_left_pix.y.value + top_right_pix.y.value) / 2) / orig_img_height\n",
    "            box_width = abs(top_right_pix.x.value - bottom_left_pix.x.value) / orig_img_width\n",
    "            box_height = abs(top_right_pix.y.value - bottom_left_pix.y.value) / orig_img_height\n",
    "\n",
    "            # Save YOLO annotation\n",
    "            yolo_filename = os.path.join(labels_folder, f'{date_str.replace(\":\", \"-\")}_AIA1600.txt')\n",
    "            os.makedirs(os.path.dirname(yolo_filename), exist_ok=True)\n",
    "            with open(yolo_filename, 'w') as f:\n",
    "                f.write(f'0 {x_center} {y_center} {box_width} {box_height}\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {jp2_filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(\"Image processing and annotation creation completed.\")\n",
    "\n",
    "# Step 3: Validate file organization\n",
    "print(\"Starting validation of file organization...\")\n",
    "data = pd.read_csv(\"ribbondb_v1.0.csv\")\n",
    "for idx, row in data.iterrows():\n",
    "    start_time = pd.to_datetime(row[' TSTART [UT]'])\n",
    "    end_time = pd.to_datetime(row[' TFINAL [UT]'])\n",
    "    \n",
    "    # Check files for this time interval\n",
    "    if not check_files_in_folders(start_time, end_time):\n",
    "        print(f\"Error: Files for row {idx} (interval {start_time} to {end_time}) are distributed across multiple folders!\")\n",
    "\n",
    "print(\"Validation completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed6bd2-532e-4fc1-8814-a72dded32062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "output_folders = ['data/train/images', 'data/val/images', 'data/test/images']\n",
    "\n",
    "# Helper function to check files in folders\n",
    "def check_files_in_folders(start_time, end_time):\n",
    "    # Generate a list of expected file names based on the time range\n",
    "    time_range = pd.date_range(start=start_time, end=end_time, freq='min')\n",
    "    expected_files = [f\"{timestamp.strftime('%Y-%m-%dT%H-%M-%S')}_AIA1600.png\" for timestamp in time_range]\n",
    "    \n",
    "    # Dictionary to store folder locations for each file\n",
    "    file_locations = {file: [] for file in expected_files}\n",
    "    \n",
    "    # Search for each file in the output folders\n",
    "    for folder in output_folders:\n",
    "        for file in expected_files:\n",
    "            if os.path.exists(os.path.join(folder, file)):\n",
    "                file_locations[file].append(folder)\n",
    "    \n",
    "    # Check if files from the same interval are in multiple folders\n",
    "    for file, locations in file_locations.items():\n",
    "        if len(locations) > 1:\n",
    "            print(f\"File {file} is found in multiple folders: {locations}\")\n",
    "    \n",
    "    # Return True if all files are in a single folder\n",
    "    return all(len(locations) <= 1 for locations in file_locations.values())\n",
    "\n",
    "# Iterate over each row in the dataset and perform the check\n",
    "for idx, row in data.iterrows():\n",
    "    start_time = pd.to_datetime(row[' TSTART [UT]'])\n",
    "    end_time = pd.to_datetime(row[' TFINAL [UT]'])\n",
    "    print(f\"Checking row {idx} with interval {start_time} to {end_time}...\")\n",
    "    \n",
    "    if not check_files_in_folders(start_time, end_time):\n",
    "        print(f\"Files for row {idx} are distributed across multiple folders!\")\n",
    "    else:\n",
    "        print(f\"All files for row {idx} are in a single folder.\")\n",
    "\n",
    "print(\"Check completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b365114d-d7fe-41ca-a866-7d811470f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_images(data, jp2_folder, output_folders, num_rows=None):\n",
    "    if num_rows is None:\n",
    "        num_rows = len(data)\n",
    "\n",
    "    print(f\"Checking {num_rows} rows from the dataset for duplicates...\")\n",
    "\n",
    "    # Helper function to determine output folder based on index\n",
    "    def get_output_folder(index):\n",
    "        if index % 10 < 7:\n",
    "            return output_folders[0]  # Train\n",
    "        elif index % 10 < 9:\n",
    "            return output_folders[1]  # Validation\n",
    "        else:\n",
    "            return output_folders[2]  # Test\n",
    "\n",
    "    # Track processed files to detect duplicates\n",
    "    processed_files = {}\n",
    "    duplicate_files = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if index >= num_rows:\n",
    "            break\n",
    "\n",
    "        lat = row[' LAT [deg]']\n",
    "        lon = row[' LON [deg]']\n",
    "        start_time = f\"{row[' TSTART [UT]']}:00\"\n",
    "        end_time = f\"{row[' TFINAL [UT]']}:00\"\n",
    "\n",
    "        # Create time range\n",
    "        time_range = pd.date_range(start=start_time, end=end_time, freq='min')\n",
    "\n",
    "        # Determine the output folder (train/val/test) for this row\n",
    "        images_folder, _ = get_output_folder(index)\n",
    "\n",
    "        for timestamp in time_range:\n",
    "            date_str = timestamp.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "            jp2_filename = os.path.join(jp2_folder, f'{date_str.replace(\":\", \"-\")}_AIA1600.jp2')\n",
    "\n",
    "            # Check if the file has already been processed\n",
    "            if date_str in processed_files:\n",
    "                duplicate_files.append((date_str, processed_files[date_str], images_folder))\n",
    "            else:\n",
    "                processed_files[date_str] = images_folder\n",
    "\n",
    "    # Report duplicates if any\n",
    "    if duplicate_files:\n",
    "        print(\"Duplicate files detected:\")\n",
    "        for date_str, folder1, folder2 in duplicate_files:\n",
    "            print(f\"File {date_str} found in both {folder1} and {folder2}\")\n",
    "    else:\n",
    "        print(\"No duplicate files detected.\")\n",
    "\n",
    "    return duplicate_files\n",
    "\n",
    "# Directory setup\n",
    "base_folder = 'data'\n",
    "jp2_folder = os.path.join(base_folder, 'jp2')\n",
    "train_images_folder = os.path.join(base_folder, 'train/images')\n",
    "train_labels_folder = os.path.join(base_folder, 'train/labels')\n",
    "val_images_folder = os.path.join(base_folder, 'val/images')\n",
    "val_labels_folder = os.path.join(base_folder, 'val/labels')\n",
    "test_images_folder = os.path.join(base_folder, 'test/images')\n",
    "test_labels_folder = os.path.join(base_folder, 'test/labels')\n",
    "annotated_folder = os.path.join(base_folder, 'annotated')\n",
    "\n",
    "output_folders = [\n",
    "    (train_images_folder, train_labels_folder),\n",
    "    (val_images_folder, val_labels_folder),\n",
    "    (test_images_folder, test_labels_folder)\n",
    "]\n",
    "\n",
    "data = pd.read_csv(\"ribbondb_v1.0.csv\")\n",
    "\n",
    "check_duplicate_images(data, 'data,jp2', output_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee440b3-71c5-4945-9d75-629182e69bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_folder = 'data/train'\n",
    "\n",
    "\n",
    "# Target precision to stop training\n",
    "target_map = 0.8  # Replace with your desired mAP threshold\n",
    "\n",
    "# Check if folders exist\n",
    "if not os.path.exists(train_folder):\n",
    "    print(\"Train folder does not exist. Please ensure the path is correct.\")\n",
    "else:\n",
    "    # Initialize YOLOv8 model\n",
    "    model = YOLO(\"runs/detect/train36/weights/epoch10.pt\")  # YOLOv8 nano model as a starting point\n",
    "\n",
    "    # Train the model on the custom dataset\n",
    "    results = model.train(\n",
    "        data='custom_data.yaml',\n",
    "        epochs=50,\n",
    "        imgsz=512,\n",
    "        batch=8,\n",
    "        hsv_h=0.0,\n",
    "        hsv_s=0.1,\n",
    "        hsv_v=0.1,\n",
    "        translate=0.0,\n",
    "        scale=0.0,\n",
    "        flipud=0.5,\n",
    "        mosaic=0.0,\n",
    "        erasing=0.0,\n",
    "        crop_fraction=0.0,\n",
    "        verbose=True,\n",
    "        patience = 10,\n",
    "        save_period = 5,\n",
    "        workers=0,\n",
    "    )\n",
    "    print(\"Training process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6fddd-492c-41ae-b85b-6dbaa6477227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"best/best.pt\")\n",
    "\n",
    "conf_values = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] \n",
    "iou_values = [0.0001, 0.001, 0.1, 0.5] \n",
    "\n",
    "for conf in conf_values:\n",
    "    for iou in iou_values:\n",
    "        metrics = model.val(conf=conf, iou=iou, save_json=True)\n",
    "\n",
    "        val_folder = metrics.save_dir\n",
    "        \n",
    "        file_path = os.path.join(val_folder, \"arguments.txt\")\n",
    "\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(f\"conf={conf}, iou={iou}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3eba9-f210-4126-8f90-45415d6b63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dictionary in COCO format\n",
    "coco = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [{\"id\": 1, \"name\": \"event\"}]\n",
    "}\n",
    "\n",
    "labels_path = \"data/val/labels\"\n",
    "images_path = \"data/val/images\"  # current directory\n",
    "annotation_id = 1\n",
    "\n",
    "# Loop through all .txt files in labels/\n",
    "for fname in os.listdir(labels_path):\n",
    "    if not fname.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    image_id = fname.replace(\".txt\", \"\")\n",
    "    image_file = image_id + \".png\"\n",
    "    image_full_path = os.path.join(images_path, image_file)\n",
    "    label_full_path = os.path.join(labels_path, fname)\n",
    "\n",
    "    if not os.path.exists(image_full_path):\n",
    "        print(f\"Image {image_file} not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Get image dimensions\n",
    "    with Image.open(image_full_path) as img:\n",
    "        width, height = img.size\n",
    "\n",
    "    # Add image metadata\n",
    "    coco[\"images\"].append({\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": image_file,\n",
    "        \"width\": width,\n",
    "        \"height\": height\n",
    "    })\n",
    "\n",
    "    # Read all objects from .txt\n",
    "    with open(label_full_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue  # skip invalid lines\n",
    "\n",
    "            cls_id, x_center, y_center, w, h = map(float, parts)\n",
    "\n",
    "            # Convert YOLO â†’ COCO format (x, y, width, height)\n",
    "            abs_x = (x_center - w / 2) * width\n",
    "            abs_y = (y_center - h / 2) * height\n",
    "            abs_w = w * width\n",
    "            abs_h = h * height\n",
    "\n",
    "            coco[\"annotations\"].append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": int(cls_id) + 1,  # Class IDs start from 1 in COCO\n",
    "                \"bbox\": [abs_x, abs_y, abs_w, abs_h],\n",
    "                \"area\": abs_w * abs_h,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            annotation_id += 1\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"ground_truth.json\", \"w\") as f:\n",
    "    json.dump(coco, f, indent=2)\n",
    "\n",
    "print(f\"Done! Total GT annotations: {len(coco['annotations'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15669367-3bc5-433b-a3e8-46dae609b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth annotations\n",
    "coco_gt = COCO(\"ground_truth.json\")\n",
    "\n",
    "# Load predictions (YOLOv8 output with save_json=True)\n",
    "coco_dt = coco_gt.loadRes(\"runs/detect/val99/predictions.json\")\n",
    "\n",
    "# Evaluate predictions using COCO metrics\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ffa16-5a7f-4842-8d62-70a7ff6f34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "image_folder = \"data/test/images\"  # Folder with input images\n",
    "output_folder = \"output\"  # Folder to save processed images\n",
    "model_path = \"best/best.pt\"  # YOLOv8 model file\n",
    "labels_folder = \"data/test/labels\"  # Folder with label files\n",
    "\n",
    "# Prediction settings\n",
    "iou_threshold = 0.0001  # IOU threshold (for filtering overlapping boxes)\n",
    "conf_threshold = 0.3  # Confidence threshold (for removing weak predictions)\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get a list of all image files\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Process each image\n",
    "for image_name in image_files:\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    label_path = os.path.join(labels_folder, os.path.splitext(image_name)[0] + \".txt\")  # Corresponding label file\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w, _ = image.shape  # Get image dimensions\n",
    "\n",
    "    # Check if label file exists\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Process bounding boxes from the label file\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                _, x_center, y_center, width, height = map(float, parts)\n",
    "\n",
    "                # Convert normalized coordinates to pixels\n",
    "                x1 = int((x_center - width / 2) * w)\n",
    "                y1 = int((y_center - height / 2) * h)\n",
    "                x2 = int((x_center + width / 2) * w)\n",
    "                y2 = int((y_center + height / 2) * h)\n",
    "\n",
    "                # Draw bounding box from labels (green)\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Run YOLOv8 prediction\n",
    "    results = model(image_path, conf=conf_threshold, iou=iou_threshold)\n",
    "\n",
    "    # Add predicted YOLO bounding boxes\n",
    "    for result in results:\n",
    "        for box in result.boxes.xyxy:\n",
    "            x1, y1, x2, y2 = map(int, box[:4])\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)  # YOLO boxes (blue)\n",
    "\n",
    "    # Save the annotated image\n",
    "    output_image_path = os.path.join(output_folder, image_name)\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    print(f\"Result saved: {output_image_path}\")\n",
    "\n",
    "print(\"Processing completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
